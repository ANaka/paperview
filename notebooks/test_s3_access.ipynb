{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import zipfile\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "class Bucket:\n",
    "    def __init__(\n",
    "        self, \n",
    "        bucket_name:str, \n",
    "        access_key=None, \n",
    "        secret_key=None, \n",
    "        requester_pays='True', \n",
    "        prefix='',\n",
    "        ):\n",
    "        # Create an S3 client using the given access and secret keys\n",
    "        self.s3_client = boto3.client('s3', aws_access_key_id=access_key, aws_secret_access_key=secret_key)\n",
    "        \n",
    "        self.bucket_name = bucket_name\n",
    "        self.requester_pays = requester_pays\n",
    "        self.prefix = prefix\n",
    "\n",
    "    \n",
    "    def list_objects(self):\n",
    "        # List the objects in the bucket, with the given prefix and requester pays flag\n",
    "        paginator = self.s3_client.get_paginator('list_objects_v2')\n",
    "        page_iterator = paginator.paginate(Bucket=self.bucket_name, Prefix=self.prefix, RequestPayer='requester')\n",
    "        for page in page_iterator:\n",
    "            for object in page['Contents']:\n",
    "                yield object\n",
    "    \n",
    "    def download_object(self, object_key, filename):\n",
    "        # Download the given object from the bucket and save it to the given filename\n",
    "        self.s3_client.download_file(\n",
    "            Bucket=self.bucket_name, \n",
    "            Key=object_key, \n",
    "            Filename=filename, \n",
    "            ExtraArgs={'RequestPayer': self.requester_pays})\n",
    "        \n",
    "        # Return the manuscript title and the files\n",
    "    def parse_manifest(self, zip_filename):\n",
    "        # Extract the zip file and parse the manifest.xml file\n",
    "        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall()\n",
    "        tree = ET.parse('manifest.xml')\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Return the manuscript title and the files in the content folder\n",
    "        title = root.find('./title')\n",
    "        files = []\n",
    "        for file in root.findall('./file'):\n",
    "            name = file.find('name').text\n",
    "            size = file.find('size').text\n",
    "            files.append((name, size))\n",
    "        return title.text, files\n",
    "    \n",
    "    def cleanup(self, zip_filename):\n",
    "        # Clean up the extracted files\n",
    "        zip_ref.close()\n",
    "        os.remove(zip_filename)\n",
    "        os.remove('manifest.xml')\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "# Set the bucket name and the requester pays flag\n",
    "bucket_name = 'biorxiv-src-monthly'\n",
    "requester_pays = True\n",
    "\n",
    "# Set the prefix to filter the objects by\n",
    "prefix = ''\n",
    "\n",
    "# Create a Bucket instance\n",
    "bucket = Bucket(bucket_name=bucket_name)\n",
    "\n",
    "objects = bucket.list_objects()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Key': 'Back_Content/Batch_01/006789a2-6c19-1014-a2c5-9e42b34c170a.meca',\n",
       " 'LastModified': datetime.datetime(2019, 11, 19, 6, 50, 27, tzinfo=tzutc()),\n",
       " 'ETag': '\"2a9838726070714b44f14684cb230415\"',\n",
       " 'Size': 1191525,\n",
       " 'StorageClass': 'STANDARD'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object = next(objects)\n",
    "object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.download_file(\n",
    "    Bucket='biorxiv-src-monthly', \n",
    "    Key='Current_Content/July_2022/ffee1f2e-6c3c-1014-a990-d896413aab59.meca', \n",
    "    Filename='temp.zip', \n",
    "    ExtraArgs={'RequestPayer': 'True'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket.download_object(object_key='Current_Content/July_2022/ffee1f2e-6c3c-1014-a990-d896413aab59.meca', filename='temp.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Iterate over the objects in the bucket\n",
    "for object in objects:\n",
    "    # Download the object\n",
    "    bucket.download_object(object['Key'], 'temp.zip')\n",
    "    \n",
    "    # Parse the manifest and print the title and file names and sizes\n",
    "    title, files = bucket.parse_manifest('temp.zip')\n",
    "    print(title)\n",
    "    for name, size in files:\n",
    "        print(f'{name}: {size} bytes')\n",
    "    \n",
    "    # Clean up\n",
    "    bucket.cleanup('temp.zip')\n",
    "\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "url = 'https://www.biorxiv.org/content/10.1101/2022.12.16.520768v1?rss=1'\n",
    "# Send an HTTP request to the URL of the webpage you want to access\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = soup.find(name='div', class_='section abstract')\n",
    "\n",
    "# Extract the text from the element\n",
    "abstract_text = element.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = soup.find('a', class_='article-dl-pdf-link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = element.get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.biorxiv.org'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_full_url = f'{base_url}{pdf_path}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.biorxiv.org/content/10.1101/2022.12.16.520768v1.full.pdf'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_full_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tempfile._TemporaryFileWrapper object at 0x11a4a0450>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import tempfile\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check that the response is successful\n",
    "if response.status_code == 200:\n",
    "    # Create a temporary file\n",
    "    with tempfile.NamedTemporaryFile(mode='wb', delete=False) as f:\n",
    "        # Write the contents of the response to the temporary file\n",
    "        f.write(response.content)\n",
    "        # Get the name of the temporary file\n",
    "        temp_file_name = f.name\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = pdf_full_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Fm0\n",
      "/Fm0\n",
      "/Fm0\n",
      "/Fm0\n",
      "/Fm0\n",
      "/Fm0\n",
      "/Fm0\n",
      "/Fm0\n",
      "/Fm0\n",
      "/Fm0\n",
      "/Fm0\n",
      "/Fm0\n",
      "/Fm0\n",
      "/Fm0\n",
      "/Fm0\n",
      "/Fm0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import tempfile\n",
    "import PyPDF2 \n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "pil_images = []\n",
    "texts = []\n",
    "# Check that the response is successful\n",
    "if response.status_code == 200:\n",
    "    # Create a temporary file\n",
    "    with tempfile.NamedTemporaryFile(mode='wb', delete=False) as f:\n",
    "        # Write the contents of the response to the temporary file\n",
    "        f.write(response.content)\n",
    "        # Get the name of the temporary file\n",
    "        temp_file_name = f.name\n",
    "\n",
    "    # Open the PDF file in read-only mode\n",
    "    with open(temp_file_name, 'rb') as f:\n",
    "        # Create a PDF object\n",
    "        pdf = PyPDF2.PdfFileReader(f)\n",
    "\n",
    "        # Get the number of pages in the PDF\n",
    "        num_pages = pdf.getNumPages()\n",
    "\n",
    "        # Iterate over the pages\n",
    "        for page_num in range(num_pages):\n",
    "            # Get the page object\n",
    "            page = pdf.getPage(page_num)\n",
    "            # Extract the text from the page\n",
    "            text = page.extractText()\n",
    "            texts.append(text)\n",
    "            \n",
    "\n",
    "            # Get the resources dictionary\n",
    "            resources = dict(page.getObject()['/Resources'])\n",
    "\n",
    "            # Check if the resources dictionary has an /XObject key\n",
    "            if '/XObject' in resources:\n",
    "                # Get the XObjects from the resources dictionary\n",
    "                xobjects = resources['/XObject']\n",
    "                # Iterate over the XObjects\n",
    "                for name, xobject in xobjects.items():\n",
    "                    # Check if the XObject is an image\n",
    "                    try:\n",
    "                        if '/Subtype' in xobject and xobject['/Subtype'] == '/Image':\n",
    "                        # Get the image object from the PDF file\n",
    "                            image_obj = pdf.getObject(xobject).getObject()\n",
    "                            # Get the image data from the image object\n",
    "                            image_data = image_obj.getData()\n",
    "                            # Create a PIL.Image object from the image data\n",
    "                            image = Image.open(io.BytesIO(image_data))\n",
    "                            # Do something with the image\n",
    "                            pil_images.append(image)\n",
    "                    except:\n",
    "                        print(name)\n",
    "\n",
    "\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pil_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Page' object has no attribute 'get_page_image_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mwith\u001b[39;00m fitz\u001b[39m.\u001b[39mopen(temp_file_name) \u001b[39mas\u001b[39;00m pdf:\n\u001b[1;32m     21\u001b[0m     \u001b[39m# Iterate over the pages in the PDF\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m pdf:\n\u001b[0;32m---> 23\u001b[0m         images \u001b[39m=\u001b[39m page\u001b[39m.\u001b[39;49mget_page_image_dict()\n\u001b[1;32m     24\u001b[0m         \u001b[39mfor\u001b[39;00m image_number, image \u001b[39min\u001b[39;00m images\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     25\u001b[0m             pil_image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mget_pil_image()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Page' object has no attribute 'get_page_image_dict'"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "from PIL import Image\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "pil_images = []\n",
    "texts = []\n",
    "# Check that the response is successful\n",
    "assert response.status_code == 200\n",
    "\n",
    "# Create a temporary file\n",
    "with tempfile.NamedTemporaryFile(mode='wb', delete=False) as f:\n",
    "    # Write the contents of the response to the temporary file\n",
    "    f.write(response.content)\n",
    "    # Get the name of the temporary file\n",
    "    temp_file_name = f.name\n",
    "\n",
    "pil_images = []\n",
    "with fitz.open(temp_file_name) as pdf:\n",
    "    # Iterate over the pages in the PDF\n",
    "    for page in pdf:\n",
    "        \n",
    "        images = page.get_page_image_dict()\n",
    "        for image_number, image in images.items():\n",
    "            pil_image = image.get_pil_image()\n",
    "            pil_images.append(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoverpix(doc, item):\n",
    "    xref = item[0]  # xref of PDF image\n",
    "    smask = item[1]  # xref of its /SMask\n",
    "\n",
    "    # special case: /SMask or /Mask exists\n",
    "    if smask > 0:\n",
    "        pix0 = fitz.Pixmap(doc.extract_image(xref)[\"image\"])\n",
    "        if pix0.alpha:  # catch irregular situation\n",
    "            pix0 = fitz.Pixmap(pix0, 0)  # remove alpha channel\n",
    "        mask = fitz.Pixmap(doc.extract_image(smask)[\"image\"])\n",
    "\n",
    "        try:\n",
    "            pix = fitz.Pixmap(pix0, mask)\n",
    "        except:  # fallback to original base image in case of problems\n",
    "            pix = fitz.Pixmap(doc.extract_image(xref)[\"image\"])\n",
    "\n",
    "        if pix0.n > 3:\n",
    "            ext = \"pam\"\n",
    "        else:\n",
    "            ext = \"png\"\n",
    "\n",
    "        return {  # create dictionary expected by caller\n",
    "            \"ext\": ext,\n",
    "            \"colorspace\": pix.colorspace.n,\n",
    "            \"image\": pix.tobytes(ext),\n",
    "        }\n",
    "\n",
    "    # special case: /ColorSpace definition exists\n",
    "    # to be sure, we convert these cases to RGB PNG images\n",
    "    if \"/ColorSpace\" in doc.xref_object(xref, compressed=True):\n",
    "        pix = fitz.Pixmap(doc, xref)\n",
    "        pix = fitz.Pixmap(fitz.csRGB, pix)\n",
    "        return {  # create dictionary expected by caller\n",
    "            \"ext\": \"png\",\n",
    "            \"colorspace\": 3,\n",
    "            \"image\": pix.tobytes(\"png\"),\n",
    "        }\n",
    "    return doc.extract_image(xref)\n",
    "dimlimit = 0  # 100  # each image side must be greater than this\n",
    "relsize = 0  # 0.05  # image : image size ratio must be larger than this (5%)\n",
    "abssize = 0  # 2048  # absolute image size limit 2 KB: ignore if smaller\n",
    "\n",
    "# Open the PDF file and get a Document object\n",
    "doc = fitz.open(temp_file_name)\n",
    "\n",
    "# Get the number of pages in the PDF\n",
    "page_count = doc.page_count\n",
    "\n",
    "# Initialize an empty list to store the images\n",
    "images = []\n",
    "\n",
    "imglist = []\n",
    "xreflist = []\n",
    "# Iterate over the pages in the PDF\n",
    "for pno in range(page_count):\n",
    "    il = doc.get_page_images(pno)\n",
    "    imglist.extend([x[0] for x in il])\n",
    "    for img in il:\n",
    "        xref = img[0]\n",
    "        if xref in xreflist:\n",
    "            continue\n",
    "        width = img[2]\n",
    "        height = img[3]\n",
    "        if min(width, height) <= dimlimit:\n",
    "            continue\n",
    "        image = recoverpix(doc, img)\n",
    "        n = image[\"colorspace\"]\n",
    "        imgdata = image[\"image\"]\n",
    "        imglist.append(imgdata)\n",
    "        xreflist.append(xref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(BytesIO(doc.extract_image(2494)['image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[197,\n",
       " 204,\n",
       " 209,\n",
       " 210,\n",
       " 252,\n",
       " 269,\n",
       " 271,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 1058,\n",
       " 1062,\n",
       " 1066,\n",
       " 1222,\n",
       " 1106,\n",
       " 1107,\n",
       " 1113,\n",
       " 1114,\n",
       " 1159,\n",
       " 1161,\n",
       " 1286,\n",
       " 1290,\n",
       " 1726,\n",
       " 1724,\n",
       " 1929,\n",
       " 1927,\n",
       " 1994,\n",
       " 1996,\n",
       " 1998,\n",
       " 2000,\n",
       " 1992,\n",
       " 2056,\n",
       " 2055,\n",
       " 2054,\n",
       " 2053,\n",
       " 2068,\n",
       " 2067,\n",
       " 2066,\n",
       " 2065,\n",
       " 2080,\n",
       " 2079,\n",
       " 2078,\n",
       " 2077,\n",
       " 2092,\n",
       " 2091,\n",
       " 2090,\n",
       " 2089,\n",
       " 2159,\n",
       " 2158,\n",
       " 2157,\n",
       " 2156,\n",
       " 2171,\n",
       " 2170,\n",
       " 2169,\n",
       " 2168,\n",
       " 2183,\n",
       " 2182,\n",
       " 2181,\n",
       " 2180,\n",
       " 2195,\n",
       " 2194,\n",
       " 2193,\n",
       " 2192,\n",
       " 2264,\n",
       " 2265,\n",
       " 2271,\n",
       " 2272,\n",
       " 2295,\n",
       " 2296,\n",
       " 2341,\n",
       " 2343,\n",
       " 2345,\n",
       " 2347,\n",
       " 2349,\n",
       " 2351,\n",
       " 2353,\n",
       " 2355,\n",
       " 2357,\n",
       " 2359,\n",
       " 2361,\n",
       " 2363,\n",
       " 2365,\n",
       " 2335,\n",
       " 2337,\n",
       " 2339,\n",
       " 2392,\n",
       " 2394,\n",
       " 2396,\n",
       " 2398,\n",
       " 2400,\n",
       " 2402,\n",
       " 2404,\n",
       " 2406,\n",
       " 2408,\n",
       " 2410,\n",
       " 2412,\n",
       " 2414,\n",
       " 2416,\n",
       " 2386,\n",
       " 2388,\n",
       " 2390,\n",
       " 2439,\n",
       " 2441,\n",
       " 2443,\n",
       " 2445,\n",
       " 2447,\n",
       " 2449,\n",
       " 2451,\n",
       " 2453,\n",
       " 2455,\n",
       " 2433,\n",
       " 2435,\n",
       " 2437,\n",
       " 2482,\n",
       " 2484,\n",
       " 2486,\n",
       " 2488,\n",
       " 2490,\n",
       " 2492,\n",
       " 2494,\n",
       " 2496,\n",
       " 2498,\n",
       " 2500,\n",
       " 2502,\n",
       " 2504,\n",
       " 2506,\n",
       " 2476,\n",
       " 2478,\n",
       " 2480,\n",
       " 2564,\n",
       " 2574,\n",
       " 2856]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xreflist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(BytesIO(imgdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAAPCAIAAAC9TIi/AAAAq0lEQVR4nO3Vuw0CUQxEUUOyy0f7ABEgWqCfrYFCyeiAasioYCwRnFPAleVkNuu6VtSyLNlgR3OM8efBx/uZDVbVdNyEg4dwcE4Hp304WFVzuhk/ct5nezXvOt4YDr4+92xwnG7p4DUbrKpxuqSD52xwm80BwI+NAaCLjQGgi40BoIuNAaCLjQGgi40BoIuNAaCLjQGgi40BoIuNAaCLjQGgi40BoIuNAaDLFx1HBldhcRSDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=545x15>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = page.get_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.get_image_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['section', 'abstract']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements[1].get(\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: div  Class: ['article', 'abstract-view']\n",
      "Name: div  Class: ['section', 'abstract']\n"
     ]
    }
   ],
   "source": [
    "for element in elements:\n",
    "    print(f'Name: {element.name}  Class: {element.get(\"class\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "element.class_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Extract the text from the element\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m text \u001b[39m=\u001b[39m element\u001b[39m.\u001b[39;49mget_text()\n\u001b[1;32m      4\u001b[0m \u001b[39m# Print the text\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(text)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract the text from the element\n",
    "text = element.get_text()\n",
    "\n",
    "# Print the text\n",
    "print(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edb4f38bb716d7593e05f21b0ca169252ffa260aa67346a4ab96ac600bffa96f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
